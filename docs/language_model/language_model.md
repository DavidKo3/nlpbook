---
layout: default
title: Language Model
nav_order: 3
has_children: true
permalink: /docs/lm
---

# 숫자 세계로 떠난 자연어
{: .no_toc }

최근의 자연어 처리는 다량의 말뭉치의 의미, 문맥을 학습한 거대한 언어모델(language model)을 활용해 문서 분류, 개체명 인식 등 각종 태스크를 수행합니다. 이 언어모델은 세부 태스크의 성능을 좌우하는데요. 요즘 들어서는 트랜스포머(transformer) 기반의 언어모델이 각광받고 있습니다. 이 장에서는 ∆ 언어모델이 말뭉치의 어떤 의미 정보를 학습하는지(Vector Semantics) ∆ 트랜스포머의 핵심 동작 원리는 무엇인지(Transformers) ∆ 트랜스포머가 기본 뼈대인 BERT, GPT 모델의 특징 등을 살펴보겠습니다.
